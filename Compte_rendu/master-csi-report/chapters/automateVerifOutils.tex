\chapter{Analyse de programmes et méthodes de vérifications}
\label{chap:automateVerifOutils}

Nous allons étudier les moyens à notre disposition pour réaliser une analyse pertinente et efficace d'un programme résistant aux attaques temporelles.

\section{Modélisation d'une attaque}

En sécurité informatique, la première étape, essentielle avant de développer une solution, c'est de produire un modèle du danger contre lequel nous souhaitons nous défendre. On parle parfois de \textit{modèle de fuite}. Cette étape de synthèse et d'abstraction est importante pour identifier les risques encourus par le futur système, souvent en identifiant les points de fuite employés par les attaques déjà publiées. \citeauthor{BewarCTSideChannel} \cite{BewarCTSideChannel} nous donne trois modèles d'adversaires à considérer lorsqu'on souhaite se défendre contre les attaques temporelles :

\begin{table}[!ht]
  \caption{Modèles d'adversaires pour les attaques temporelles \cite{BewarCTSideChannel}}
  \label{tab:temporal_attacks}
  \begin{adjustbox}{width=\textwidth}
  \begin{tabularx}{\textwidth}{|L|L|}
    \hline
    \rowcolor{lightgray}
    \multicolumn{1}{|C|}{\textbf{Type d'attaque}} & \multicolumn{1}{C|}{\textbf{Description}} \\ \hline
    Par chronométrage & Observation du temps de calcul. \\ \hline
    Par accès mémoire & Manipulation et observation des états d'un ou de plusieurs caches mémoire. \\ \hline
    Par récupération de traces & Suivi des appels de fonctions, des accès réussis ou manqués à la mémoire. \\ \hline
  \end{tabularx}
  \end{adjustbox}
\end{table}

Ces types d'attaques forment une base pour la conception de nos modèles d'attaquant. Considérer le mode opératoire <<récupération de traces>> induit un modèle plus puissant. Des travaux comme ceux de \citeauthor{twartingCT} \cite{twartingCT} portent directement sur des améliorations matérielles permettant une défense contre ce modèle. Considérer un hypothétique attaquant plus puissant, avec des accès à des ressources supplémentaires, permet de concevoir un système plus sûr. Certains outils comme \cite{ctfuzz,DATA2} ou cette étude \cite{notThatHardCT} exploitent notamment cette mécanique pour attester de la sécurité d'un programme.\medbreak


Puis, avec ces modèles et les contre-mesures connues, nous pouvons constituer un ensemble de règles qui vérifient ces risques. \cite{CTsaferCrypto} résume celles-ci en une liste de trois règles :
\begin{enumerate}
  \item Toute boucle révèle le nombre d'itérations effectuées. 
  \item Tout accès mémoire révèle l'adresse (ou l'indice) accédée.
  \item Toute instruction conditionnelle révèle quelle branche a été prise.
\end{enumerate}

Avec ces règles, il est alors possible de créer un outil qui analyse les programmes à sécuriser. C'est ainsi que le premier outil existant a été produit : \texttt{ctgrind} (2010).\medbreak

D'autres chercheurs comme \citeauthor{binsecRel2019} \cite{binsecRel2019} s'attellent à la création de modèles formels. Cette méthode demande un travail de formalisation du comportement de programmes binaires et une implémentation plus rigoureuse de leurs outils. Cela permet en retour une évaluation complète et correcte de programmes complexes (\ie primitives cryptographiques asymétriques).

\subsection*{Formalisation de modèle - \cite{binsecRel2019}}

Si nous voulons concevoir un modèle formel, nous pouvons nous appuyer sur l'article \citetitle{formalConstantTime} \cite{formalConstantTime}.\medbreak


Nous commençons par définir un programme. Il s'agit d'une suite d'instructions binaires. Et une instruction est une action sur la mémoire. Cela nous permet de définir notre programme comme une suite de configurations $(l,r,m)$; $l$ la ligne d'instruction, $r$ le dictionnaire de registre et $m$ la mémoire. La configuration initiale est définie par $c_0 \triangleq (l_0,r_0,m_0)$ où $l_0$ est l'adresse de l'instruction d'entrée du programme, $r_0$ un dictionnaire de registres vide et $m_0$ une mémoire vide.\smallbreak

Ainsi, avec cette modélisation, une instruction est un changement appliqué à notre configuration. Ce changement peut être représenté par $ c_0 \underset{t}{\to} c_1 $, $c_0$ et $c_1$ sont deux configurations successives, $\to$ la transition entre les deux et $t$ une fuite émise par cette transition. Notons que certaines instructions ne produisent pas de fuites.\smallbreak

Une fois ce préambule installé nous définissons formellement le comportement de nos instructions. Regardons par exemple comment se formalise un chargement :

\begin{figure}[!ht]
  \caption{Instruction \texttt{chargement}}
  \label{fig:instr_load}
  \centering
  
    % version avec \scalebox
    \scalebox{1.8}{% agrandir à 150%
    $\smash{\scalebox{0.5556}{\textsc{LOAD}}}\quad
    \frac{(l,r,m)\; e \vdash_t \text{bv}}
         {(l,r,m)\; @ \; e \vdash_{t.[\text{bv}]} m \;\text{bv}}$
    }
\end{figure}

Ici, l'évaluation de l'expression \texttt{e} sur une configuration $(l,r,m)$ produit une fuite de la valeur $bv$. En haut nous retrouvons la notation de l'opération effectuée et au-dessous la formalisation de la fuite : $t \cdot [bv]$ signifie que la valeur $bv$ s'ajoute à la liste des fuites. Ce second exemple \ref{fig:instr_branchement} présente une opération de branchement en fonction de $e$ vers les instructions $l_1$ et $l_2$. Nous voyons que la valeur est différente de zéro, ce qui nous produit une fuite vers l'instruction $l_1$. Cette fuite est à ajouter à notre liste $t$.

\begin{figure}[!ht]
  \caption{Instruction \texttt{branchement}}
  \label{fig:instr_branchement}
  \centering
  \scalebox{1.8}{
    $\smash{\scalebox{0.5556}{\textsc{T-ITE}}}\quad
        \frac{
        P.l = \textit{ite } e \,?\, l_1 : l_2 \quad(l, r, m) \vdash_t \text{bv} \quad \text{bv} \neq 0}
        {(l, r, m)\; \underset{t[l_1]}{\longrightarrow}\; (l_1, r, m)}$
    }
\end{figure}

Nous pouvons retrouver l'ensemble des règles formelles en Annexe \ref{fig:ensemble_instr_formelles}.

\section{Analyse d'un programme}

Nous savons concevoir un modèle pour contrôler ou détecter les erreurs. Nous pouvons maintenant concevoir notre analyse pour vérifier ce modèle sur un programme. Plusieurs techniques de vérification existent et nous allons les passer en revue : \cite{GeimerEvaluationsSideChannel}.\medbreak


\subsection*{Analyse statique}

Cette méthode consiste à déduire le fonctionnement d'un programme. Nous souhaitons vérifier que son fonctionnement respecte les propriétés de sécurité définies préalablement. Cette analyse sans exécution réalise une simulation du programme en explorant les chemins d'exécution possibles. De fait, les résultats obtenus sont souvent approximés car une exploration totale peut se révéler irréalisable. Historiquement il s'agit de la première méthode étudiée/employée et depuis elle a été dérivée en plusieurs approches.\medbreak

\paragraph{Non-interférence} Pour renforcer les résultats obtenus et réduire le nombre de faux positifs nous pouvons vérifier la propriété de non-interférence. Cette propriété est inhérente aux programmes. Un programme a des entrées et des sorties. Celles-ci peuvent être classées \textit{faibles} (peu importantes) ou \textit{hautes} (données secrètes, sensibles). Un programme est non-trois modèles d'adversaires à considérer lorsqu'on souhaite se interférent si et seulement si pour n'importe quelle entrée faible le programme ressort la même sortie faible peu importe les valeurs des entrées hautes qui peuvent être précisées.

Appliqué à une analyse statique pour la vérification de programme, la mesure des ressources employées par l'ordinateur permet d'avoir une sortie faible pour comparer le comportement d'un programme en fonction de ses entrées (ici considérées secrètes).

\paragraph{\textit{Self-Composition}}\footnote{Construction personnelle, le terme anglais est conservé.} La self-composition consiste à entrelacer deux exécutions d'un programme $P$ avec différents ensembles de variables secrètes dans un seul programme auto-composé $P;P'$. Des solveurs peuvent alors être utilisés pour vérifier la propriété de non-interférence. Cette approche a été utilisée par \citeauthor{ABPV13} \cite{ABPV13} pour vérifier manuellement des exemples limités, nécessitant de nombreuses annotations pour limiter l'explosion (quadratique) des états à comparer et explorer. \cite{binsecRel2019} emploie cette approche associée à des solveurs SMT pour vérifier uniquement les propriétés définies dans leur modèle. La restriction aux propriétés temps constant permet l'exploitation de cette méthode sans le contrecoup de l'augmentation de la taille des formules.

\paragraph{Systèmes de types} Cette approche diffère des précédentes car elle nécessite un travail supplémentaire du développeur. Il doit ajouter la spécification \texttt{secret} aux valeurs employées pour que cette information se diffuse dans le compilateur et que des mesures adaptées soient effectuées au niveau du binaire. Cette approche est intéressante car elle permet une flexibilité plus importante lors de la production du code et permet de s'abstenir des contre-mesures décrites au chapitre \ref{chap:constantTimeSolution}. En revanche elle nécessite un compilateur spécialisé et aucune vérification sur le binaire produit n'est effectuée. 

\paragraph{Interprétation abstraite} Un programme est (généralement) trop complexe pour être entièrement formellement vérifié, donc il y a une sur-approximation des états atteignables par l'analyse. Ainsi, si l'analyse approximée est sécurisée alors le programme est sécurisé. Cette approche se retrouve dans CacheAudit \cite{CacheAudit} : modélisation par un graphe de flot de l'état des caches, de la mémoire et des successions d'évènements.

\paragraph{Exécution symbolique} L'exécution symbolique consiste à exécuter le programme avec des entrées symboliques. Les chemins explorés sont associés à une formule logique, et un solveur vérifie si un ensemble de valeurs concrètes satisfait les formules générées. Cette méthode est utilisée pour vérifier l'absence de dépendance aux secrets dans les comportements temporels ou mémoire du programme.

\subsection*{Analyse dynamique}

L'analyse dynamique emploie la preuve par l'exemple pour garantir la sécurité du programme cible. Nous exécutons le programme et nous collectons sa trace : informations issues des évènements (accès mémoire, sauts,\etc) rencontrés au fur et à mesure de l'exécution. Les approches diffèrent dans la collecte et la production de ces traces.

\paragraph{Trace unique} Explorer tous les comportements d'un programme est coûteux en temps, et pour les besoins du développement il peut être préférable d'étudier quelques cas particuliers entièrement. Cette approche simplifie le modèle de l'attaquant et réalise sa vérification plus rapidement. \texttt{ctgrind} \cite{ctgrind} réutilise l'analyse dynamique de Valgrind pour vérifier les propriétés temps constant. Pour ajouter de la précision, il est possible d'utiliser l'exécution symbolique pour rejouer la trace avec le secret comme valeur symbolique et vérifier la violation du temps constant (CacheD \cite{CacheD}).

\paragraph{Comparaison de traces} Les tests statistiques peuvent vérifier si différents secrets induisent des différences significatives dans les traces enregistrées. Des outils comme DATA \cite{DATA1} ou MicroWalk \cite{MicroWalk} utilisent diverses méthodes statistiques ou d'apprentissage pour détecter et localiser les fuites. D'autres outils comme dudect \cite{dudect} enregistrent simplement le nombre total de cycles d'horloge et comparent leur distribution selon les secrets.

Le fuzzing peut aussi être utilisé pour trouver des entrées maximisant la couverture et la fuite via canal auxiliaire, comme dans ct-fuzz \cite{ctfuzz}.\medbreak


\section{Outils de vérifications}
% https://blog.cr.yp.to/20240803-clang.html


Nous avons présenté rapidement de nombreux outils capables d'effectuer de la vérification de binaire (voir la table \ref{tab:tools_ct}) et tout au long de la section précédente nous avons présenté les méthodes employées par ceux-ci. \medbreak

Ils sont tous conçus pour analyser spécialement type de fichier (C, Java, LLVM, \etc). Dans notre cas nous ciblons des binaires. Nous pouvons donc nous tourner vers ces candidats :
\begin{itemize}
\begin{multicols}{4}
  \item Binsec
  \item CacheAudit
  \item ctgrind
  \item DATA
  \item dudect
  \item KMO
  \item MicroWalk
  \item timecop
\end{multicols}
\end{itemize}

\subsection*{Outils obsolète ou inadéquat}

\texttt{ctgrind} et \texttt{timecop} sont tous les deux bâtis sur \textit{Valgrind}. L'analyse se base sur l'outil de détection d'erreur mémoire propre à \textit{Valgrind} : \textit{Memcheck}. Celui-ci détecte les branchements conditionnels et les accès mémoire calculés vers des régions non initialisées. Les vulnérabilités sont trouvées en marquant les variables secrètes comme non définies, au travers d'une annotation de code spécifique. Puis, durant l'exécution, \textit{Memcheck} associe chaque bit de données manipulées par le programme avec un bit de définition qu'il propage tout au long de l'analyse et qu'il vérifie lors d'un calcul d'une adresse ou d'un saut. Appliquée à \textit{Valgrind} l'analyse est pertinente. Cependant, dans le cadre de la recherche de failles temporelles cette approche produit un nombre considérable de faux positifs, car des erreurs non liées aux valeurs secrètes sont également rapportées.\medbreak


\texttt{KMO} détecte les fuites d'information pour des attaques qui ciblent le cache. Cet outil développé en 2012 et n'est plus maintenu, utilisait une représentation interne du binaire pour compter les bits d'informations qui peuvent fuiter. En initialisation, l'outil fait deux estimations (borne supérieure et inférieure) de la quantité d'informations qu'un attaquant peut extraire en observant les adresses mémoire présentes dans le cache après l'exécution d'un programme. Grâce à l'observation qu'une estimation haute du nombre d'états atteignables par le programme est aussi une estimation haute du nombre de bits que peut connaître un attaquant, on peut déterminer la sécurité d'un programme.


\subsection*{Outils statistiques}

\texttt{dudect} détecte les fuites temporelles par des mesures répétées du temps d'exécution et une comparaison à l'aide d'un test statistique. Le binaire est exécuté sous deux classes différentes d'entrées secrètes : un ensemble avec des valeurs constantes et un ensemble avec des valeurs sélectionnées aléatoirement avant chaque mesure. Les temps d'exécution de la fonction cible sont alors enregistrés en sondant les compteurs de cycles CPU. Si les deux distributions sont distinguables, alors une fuite est rapportée uniquement si la valeur dépasse un seuil (prédéfini). Les garanties apparaissent à partir d'un grand nombre de mesures.\medbreak

\texttt{MicroWalk} enregistre plusieurs exécutions de la fonction cible avec différentes entrées. La trace enregistrée contient les cibles des branches et les adresses mémoire rencontrées pendant l’exécution. Des scores d’information mutuelle (MI) sont ensuite calculés entre la trace de fuite et l’ensemble des entrées, fournissant une quantification du nombre de bits d’entrée divulgués. \texttt{MicroWalk} propose différents compromis entre granularité du score MI et performance, allant de l’information mutuelle sur l’ensemble du programme (quantification grossière des fuites) jusqu’à des instructions individuelles (pour localiser précisément les fuites).\medbreak

\texttt{DATA} identifie les vulnérabilités par canaux auxiliaires basées sur les adresses grâce à une analyse dynamique. Premièrement, une phase de collecte des traces d’adresses. En comparant ces traces, il identifie des différences au niveau des adresses, indiquant d’éventuelles fuites. Cependant, de nombreuses différences proviennent des entrées publiques et ne sont donc pas critiques. Pour filtrer ces faux positifs, \texttt{DATA} utilise des tests statistiques. La deuxième phase teste si les différences dépendent de la clé privée en comparant des traces générées à partir d’une clé fixe avec des traces générées à partir de clés variables. Ce test entre fixe et aléatoire nécessite un contrôle sur la variable secrète. Enfin il y a une phase de classement des fuites pour détecter les relations entre les traces d’adresses et le secret.\medbreak


\subsection*{Outils formels}


\texttt{CacheAudit} prend en entrée un binaire de programme et une configuration de cache, et il en déduit des garanties de sécurité formelles et quantitatives adaptées à un jeu de modèles d'attaquants par canaux auxiliaires (observation des états de cache, des traces d'utilisation de caches et de chronométrage des temps d’exécution). Le principal défaut est l'usage limité à l'architecture x86\_64.\medbreak


\texttt{Binsec} est une plateforme d'outils. On peut concevoir des scripts ou des extensions pour diriger les analyses qu'il effectue. Il a notamment une extension qui permet d'exploiter l'exécution symbolique pour vérifier les propriétés de temps constant d'un binaire. \texttt{Binsec} détecte l'architecture du binaire puis convertit les instructions en une représentation interne (RI) codée en DBA. À partir de la RI, il réalise une exécution symbolique avec une vérification de la non-interférence et vérifie qu'aucune dépendance aux entrées secrètes n'existe.\medbreak

\subsection*{Choix de notre outil d'analyse}

Au regard du tour d'horizon des outils que nous venons d'effectuer, seul \texttt{Binsec} peut être retenu pour la suite du projet. L'analyse n'est pas statistique, elle nous permet de couvrir plusieurs architectures, et nous pouvons l'adapter à tous les binaires qui peuvent être issus d'une bibliothèque cryptographique. Un défaut que nous pouvons observer est sa complexité. \texttt{Binsec} est une plateforme d'outils (27) et prendre en main toutes ses possibilités n'est pas évident.


\vfill
\textit{Cette première partie se conclut avec des réponses pour nos deux premières questions de recherche. Conserver les garanties de sécurité tout au long de la compilation est réalisable mais ne permet pas d'avoir un service utilisable sur différentes architectures. D'un autre côté nous avons pu mettre la main sur un outil d'analyse de binaire qui nous permettra d'effectuer la vérification d'une bibliothèque cryptographique. Nous allons maintenant nous pencher sur la réalisation d'un processus d'automatisation de la vérification d'un binaire.}